{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div style=\"text-align: center\"> Introduction to Python and Machine Learning\n",
    "\n",
    "## <div style=\"text-align: center\">Machine Learning in Python (III) - Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![logo](data:image/jpeg;base64,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)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Anaconda/Miniconda\n",
    "\n",
    "\n",
    "### Creating the environment in anaconda (with a specific Python version):\n",
    "\n",
    "conda create --name keras python=3.9.7 (you can decide which Python version you want depending on the library you use. For keras it will be Python 3.9 which can be found in the documentation)\n",
    "\n",
    "### Activating the environment:\n",
    "\n",
    "conda activate keras\n",
    "\n",
    "### Installing libraries:\n",
    "\n",
    "When you first install the myenv environment then you HAVE to install additional libraries (pandas, seaborn, keras, and jupyter (and others if you need them)\n",
    "\n",
    "conda install pandas seaborn jupyter keras sklearn\n",
    "\n",
    "\n",
    "REMEMBER that you have to activate the environment each time you open terminal or anaconda prompt when you want to work with keras!!!\n",
    "\n",
    "You can check the list of available environments using:\n",
    "\n",
    "conda env list\n",
    "\n",
    "### Activating your environment:\n",
    "conda activate YOUR_ENV_NAME\n",
    "\n",
    "### Set working directory:\n",
    "cd path\n",
    "\n",
    "### Start jupyter notebook:\n",
    "jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to display the points we use the predefined (by us) `plot_decision` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following means \"from imports_for_ML.py import everything\"\n",
    "from imports_for_ML import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural networks algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "üì∫ ************* WATCH AT HOME - a WONDERFUL introduction to Artificial Neural Networks *************\n",
    "<br>\n",
    "\n",
    "https://www.3blue1brown.com/neural-networks\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural networks\n",
    "Our plan:\n",
    "* Introduction to the Keras library.\n",
    "* The simplest neural network, equivalent of logistic regression\n",
    "* Examples of neural network behavior with different number of neurons and layers for simple data with two predictive factors\n",
    "* A neural network implemented on Titanic data\n",
    "\n",
    "Then we will move on to the use of neural networks in image analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "üì∫ ************* WATCH AT HOME *************\n",
    "<br>\n",
    "\n",
    "[Keras Explained](https://www.youtube.com/watch?v=j_pJmXJwMLA)\n",
    "\n",
    "[Layers in a Neural Network explained](https://www.youtube.com/watch?v=FK77zZxaBoI)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "üì∫ ************* WATCH AT HOME *************\n",
    "<br>\n",
    "\n",
    "[Which Activation Function Should I Use? - VERY GOOD VIDEO about RELU!](https://www.youtube.com/watch?v=-7scQpJT7uo)\n",
    "\n",
    "[Activation Functions in a Neural Network explained](https://www.youtube.com/watch?v=m0pIlLfpXWE)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Keras` is the simplest library for neural networks in Python. It is high-level, which means that many details are done automatically, and allows us to focus on the \"big picture\". Keras is known for its well-designed API (programming interface), which makes it very convenient to use. Today we will use a simple sequential network (`Sequential`), for which subsequent layers are connected on a case-by-case basis (`Dense` type connection).  \n",
    "\n",
    "Installing keras (from the `Anaconda Prompt` application): \n",
    "\n",
    "`conda install keras`\n",
    "\n",
    "OR\n",
    "\n",
    "`pip install keras`\n",
    "\n",
    "---\n",
    "\n",
    "We will import the appropriate objects first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "‚ö†Ô∏èTASK 1\n",
    "<br>\n",
    "\n",
    "We will also create an artificial dataset using the `make_moons` function. We would like to create `250` points, with a noise level of `0.25` and a `random_state` as `23` (to get similar results on the n-th run of our function):\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X_moon, y_moon = make_moons(n_samples=250, noise=0.25, random_state=23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the `plot_decision` function we already know to display the data we have created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_decision(X_moon, y_moon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "‚ö†Ô∏èTASK 2\n",
    "<br>\n",
    "\n",
    "But this time we will check the correctness on the training and test data. Therefore, we divide the data into test and training data. Let the test data account for 25% of all data.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_moon_train, X_moon_test, y_moon_train, y_moon_test = train_test_split(X_moon, y_moon, test_size=0.25, random_state=23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a sequential network, we first use `Sequential` - this way we will create an empty space (without layers yet) - to which we will \"stick\" the consequtive layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "‚ö†Ô∏èTASK 3\n",
    "<br>\n",
    "\n",
    "Apply a \"dense\" layer first. (`Dense`) - i.e. one in which each neuron is connected to each other in the previous layer.  \n",
    "* The first argument for the `Dense` is the number of neurons - we want only one neuron for now.\n",
    "* We also want to set the type of activation for the added layer; the activation determines how the neurons transform the incoming signal. Because this one added neuron will also be an output neuron, we want it to have an activation of the `'sigmoid'` type (like a logistic function) - i.e. a minimum value of 0 and a maximum of 1. The activity of this neuron will determine whether the point belongs to the blue group (value zero) or to the orange group (value one).\n",
    "* The neuron added by us is simultaneously the output neuron and the first one adjacent to the data, therefore it needs to know what is the size of this data (`input_shape`). Our data has two predictors (values on the x-axis and values on the y-axis), so we give `input_shape=(2,)` (we give dimensions as a *tuple* type `(2,)`. Because the data could have e.g. height and width as in the case of photos, we would give `(height, width)`). \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(1, activation='sigmoid', input_shape=(2,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To display a summary of the created model, use the `summary` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3\n",
      "Trainable params: 3\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first network is very modest - only 3 parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to compile the model, i.e. prepare it to run. When compiling, we specify the cost function (`loss`), the optimization method (`optimizer`). We can also ask for some values to be calculated for the next steps of fitting the model (`metrics`).  \n",
    "* We want the cost function to be `'binary_crossentropy'` (we will always use it for classification problems).\n",
    "* Optimizer is set to `'adam'`, a popular optimization method that often leads to faster network learning.\n",
    "* We also want to calculate the correctness for the next steps of network fit (`['accuracy']`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to fit the model to the data, we use the familiar method `.fit` - we provide the training data to it: predictors and classifications. We also want to define how long the network is going to learn, most often we define it in the so-called epochs. One epoch is the use of all observations in training. Let us choose `250` epochs. Additionally, we use the `verbose` argument and set it to `0` in order not to clutter the screen with messages about training progress (for such small data the training will be very fast, we do not need information about progress)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.8912 - accuracy: 0.4225\n",
      "Epoch 2/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.8883 - accuracy: 0.4225\n",
      "Epoch 3/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.8854 - accuracy: 0.4171\n",
      "Epoch 4/250\n",
      "6/6 [==============================] - 0s 912us/step - loss: 0.8824 - accuracy: 0.4171\n",
      "Epoch 5/250\n",
      "6/6 [==============================] - 0s 618us/step - loss: 0.8794 - accuracy: 0.4171\n",
      "Epoch 6/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.8765 - accuracy: 0.4171\n",
      "Epoch 7/250\n",
      "6/6 [==============================] - 0s 815us/step - loss: 0.8736 - accuracy: 0.4171\n",
      "Epoch 8/250\n",
      "6/6 [==============================] - 0s 944us/step - loss: 0.8709 - accuracy: 0.4171\n",
      "Epoch 9/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.8679 - accuracy: 0.4171\n",
      "Epoch 10/250\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.8652 - accuracy: 0.4225\n",
      "Epoch 11/250\n",
      "6/6 [==============================] - 0s 881us/step - loss: 0.8623 - accuracy: 0.4225\n",
      "Epoch 12/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.8596 - accuracy: 0.4332\n",
      "Epoch 13/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.8570 - accuracy: 0.4332\n",
      "Epoch 14/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.8543 - accuracy: 0.4332\n",
      "Epoch 15/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.8516 - accuracy: 0.4385\n",
      "Epoch 16/250\n",
      "6/6 [==============================] - 0s 575us/step - loss: 0.8488 - accuracy: 0.4385\n",
      "Epoch 17/250\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.8462 - accuracy: 0.4332\n",
      "Epoch 18/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.8435 - accuracy: 0.4332\n",
      "Epoch 19/250\n",
      "6/6 [==============================] - 0s 779us/step - loss: 0.8409 - accuracy: 0.4332\n",
      "Epoch 20/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.8383 - accuracy: 0.4332\n",
      "Epoch 21/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.8356 - accuracy: 0.4332\n",
      "Epoch 22/250\n",
      "6/6 [==============================] - 0s 764us/step - loss: 0.8332 - accuracy: 0.4332\n",
      "Epoch 23/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.8306 - accuracy: 0.4385\n",
      "Epoch 24/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.8281 - accuracy: 0.4385\n",
      "Epoch 25/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.8254 - accuracy: 0.4385\n",
      "Epoch 26/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.8229 - accuracy: 0.4385\n",
      "Epoch 27/250\n",
      "6/6 [==============================] - 0s 799us/step - loss: 0.8207 - accuracy: 0.4385\n",
      "Epoch 28/250\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.8180 - accuracy: 0.4332\n",
      "Epoch 29/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.8156 - accuracy: 0.4439\n",
      "Epoch 30/250\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.8132 - accuracy: 0.4385\n",
      "Epoch 31/250\n",
      "6/6 [==============================] - 0s 600us/step - loss: 0.8108 - accuracy: 0.4385\n",
      "Epoch 32/250\n",
      "6/6 [==============================] - 0s 0s/step - loss: 0.8085 - accuracy: 0.4439\n",
      "Epoch 33/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.8060 - accuracy: 0.4492\n",
      "Epoch 34/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.8036 - accuracy: 0.4492\n",
      "Epoch 35/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.8014 - accuracy: 0.4439\n",
      "Epoch 36/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.7990 - accuracy: 0.4439\n",
      "Epoch 37/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.7967 - accuracy: 0.4492\n",
      "Epoch 38/250\n",
      "6/6 [==============================] - 0s 600us/step - loss: 0.7944 - accuracy: 0.4492\n",
      "Epoch 39/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.7922 - accuracy: 0.4545\n",
      "Epoch 40/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.7899 - accuracy: 0.4545\n",
      "Epoch 41/250\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7877 - accuracy: 0.4545\n",
      "Epoch 42/250\n",
      "6/6 [==============================] - 0s 600us/step - loss: 0.7854 - accuracy: 0.4599\n",
      "Epoch 43/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.7833 - accuracy: 0.4599\n",
      "Epoch 44/250\n",
      "6/6 [==============================] - 0s 799us/step - loss: 0.7811 - accuracy: 0.4652\n",
      "Epoch 45/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.7788 - accuracy: 0.4652\n",
      "Epoch 46/250\n",
      "6/6 [==============================] - 0s 600us/step - loss: 0.7768 - accuracy: 0.4706\n",
      "Epoch 47/250\n",
      "6/6 [==============================] - 0s 600us/step - loss: 0.7745 - accuracy: 0.4706\n",
      "Epoch 48/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.7726 - accuracy: 0.4706\n",
      "Epoch 49/250\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7703 - accuracy: 0.4759\n",
      "Epoch 50/250\n",
      "6/6 [==============================] - 0s 761us/step - loss: 0.7682 - accuracy: 0.4706\n",
      "Epoch 51/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.7662 - accuracy: 0.4706\n",
      "Epoch 52/250\n",
      "6/6 [==============================] - 0s 600us/step - loss: 0.7641 - accuracy: 0.4706\n",
      "Epoch 53/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.7620 - accuracy: 0.4706\n",
      "Epoch 54/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.7600 - accuracy: 0.4813\n",
      "Epoch 55/250\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7580 - accuracy: 0.4813\n",
      "Epoch 56/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.7561 - accuracy: 0.4759\n",
      "Epoch 57/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.7540 - accuracy: 0.4759\n",
      "Epoch 58/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.7520 - accuracy: 0.4813\n",
      "Epoch 59/250\n",
      "6/6 [==============================] - 0s 775us/step - loss: 0.7501 - accuracy: 0.4813\n",
      "Epoch 60/250\n",
      "6/6 [==============================] - 0s 600us/step - loss: 0.7481 - accuracy: 0.4813\n",
      "Epoch 61/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.7462 - accuracy: 0.4813\n",
      "Epoch 62/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.7442 - accuracy: 0.4813\n",
      "Epoch 63/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.7424 - accuracy: 0.4813\n",
      "Epoch 64/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.7405 - accuracy: 0.4813\n",
      "Epoch 65/250\n",
      "6/6 [==============================] - 0s 789us/step - loss: 0.7385 - accuracy: 0.4813\n",
      "Epoch 66/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.7367 - accuracy: 0.4813\n",
      "Epoch 67/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.7348 - accuracy: 0.4759\n",
      "Epoch 68/250\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7330 - accuracy: 0.4759\n",
      "Epoch 69/250\n",
      "6/6 [==============================] - 0s 600us/step - loss: 0.7313 - accuracy: 0.4759\n",
      "Epoch 70/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.7294 - accuracy: 0.4813\n",
      "Epoch 71/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.7276 - accuracy: 0.4866\n",
      "Epoch 72/250\n",
      "6/6 [==============================] - 0s 600us/step - loss: 0.7258 - accuracy: 0.4866\n",
      "Epoch 73/250\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7240 - accuracy: 0.4813\n",
      "Epoch 74/250\n",
      "6/6 [==============================] - 0s 989us/step - loss: 0.7222 - accuracy: 0.4813\n",
      "Epoch 75/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.7205 - accuracy: 0.4813\n",
      "Epoch 76/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.7187 - accuracy: 0.4813\n",
      "Epoch 77/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.7171 - accuracy: 0.4813\n",
      "Epoch 78/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.7153 - accuracy: 0.4813\n",
      "Epoch 79/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.7135 - accuracy: 0.4813\n",
      "Epoch 80/250\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7120 - accuracy: 0.4866\n",
      "Epoch 81/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.7102 - accuracy: 0.4866\n",
      "Epoch 82/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.7086 - accuracy: 0.4866\n",
      "Epoch 83/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 801us/step - loss: 0.7069 - accuracy: 0.4866\n",
      "Epoch 84/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.7053 - accuracy: 0.4973\n",
      "Epoch 85/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.7037 - accuracy: 0.4973\n",
      "Epoch 86/250\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7020 - accuracy: 0.4973\n",
      "Epoch 87/250\n",
      "6/6 [==============================] - 0s 824us/step - loss: 0.7005 - accuracy: 0.5027\n",
      "Epoch 88/250\n",
      "6/6 [==============================] - 0s 600us/step - loss: 0.6988 - accuracy: 0.5027\n",
      "Epoch 89/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6973 - accuracy: 0.5134\n",
      "Epoch 90/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6957 - accuracy: 0.5134\n",
      "Epoch 91/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6941 - accuracy: 0.5134\n",
      "Epoch 92/250\n",
      "6/6 [==============================] - 0s 600us/step - loss: 0.6926 - accuracy: 0.5134\n",
      "Epoch 93/250\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.5134\n",
      "Epoch 94/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6896 - accuracy: 0.5134\n",
      "Epoch 95/250\n",
      "6/6 [==============================] - 0s 795us/step - loss: 0.6880 - accuracy: 0.5241\n",
      "Epoch 96/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6865 - accuracy: 0.5241\n",
      "Epoch 97/250\n",
      "6/6 [==============================] - 0s 803us/step - loss: 0.6851 - accuracy: 0.5241\n",
      "Epoch 98/250\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.6836 - accuracy: 0.5241\n",
      "Epoch 99/250\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.6821 - accuracy: 0.5241\n",
      "Epoch 100/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6806 - accuracy: 0.5241\n",
      "Epoch 101/250\n",
      "6/6 [==============================] - 0s 600us/step - loss: 0.6792 - accuracy: 0.5241\n",
      "Epoch 102/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6778 - accuracy: 0.5241\n",
      "Epoch 103/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6763 - accuracy: 0.5187\n",
      "Epoch 104/250\n",
      "6/6 [==============================] - 0s 803us/step - loss: 0.6749 - accuracy: 0.5241\n",
      "Epoch 105/250\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.6735 - accuracy: 0.5294\n",
      "Epoch 106/250\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.6720 - accuracy: 0.5294\n",
      "Epoch 107/250\n",
      "6/6 [==============================] - 0s 794us/step - loss: 0.6707 - accuracy: 0.5348\n",
      "Epoch 108/250\n",
      "6/6 [==============================] - 0s 600us/step - loss: 0.6694 - accuracy: 0.5401\n",
      "Epoch 109/250\n",
      "6/6 [==============================] - 0s 600us/step - loss: 0.6680 - accuracy: 0.5401\n",
      "Epoch 110/250\n",
      "6/6 [==============================] - 0s 803us/step - loss: 0.6666 - accuracy: 0.5401\n",
      "Epoch 111/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6653 - accuracy: 0.5455\n",
      "Epoch 112/250\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.6639 - accuracy: 0.5455\n",
      "Epoch 113/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6626 - accuracy: 0.5508\n",
      "Epoch 114/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.6612 - accuracy: 0.5561\n",
      "Epoch 115/250\n",
      "6/6 [==============================] - 0s 600us/step - loss: 0.6600 - accuracy: 0.5561\n",
      "Epoch 116/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6587 - accuracy: 0.5561\n",
      "Epoch 117/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6574 - accuracy: 0.5561\n",
      "Epoch 118/250\n",
      "6/6 [==============================] - 0s 600us/step - loss: 0.6560 - accuracy: 0.5508\n",
      "Epoch 119/250\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.6549 - accuracy: 0.5508\n",
      "Epoch 120/250\n",
      "6/6 [==============================] - 0s 594us/step - loss: 0.6536 - accuracy: 0.5508\n",
      "Epoch 121/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6523 - accuracy: 0.5508\n",
      "Epoch 122/250\n",
      "6/6 [==============================] - 0s 799us/step - loss: 0.6511 - accuracy: 0.5508\n",
      "Epoch 123/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.6498 - accuracy: 0.5508\n",
      "Epoch 124/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6486 - accuracy: 0.5455\n",
      "Epoch 125/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6474 - accuracy: 0.5401\n",
      "Epoch 126/250\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.6462 - accuracy: 0.5401\n",
      "Epoch 127/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6450 - accuracy: 0.5401\n",
      "Epoch 128/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.6438 - accuracy: 0.5401\n",
      "Epoch 129/250\n",
      "6/6 [==============================] - 0s 600us/step - loss: 0.6426 - accuracy: 0.5455\n",
      "Epoch 130/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6414 - accuracy: 0.5508\n",
      "Epoch 131/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.6403 - accuracy: 0.5508\n",
      "Epoch 132/250\n",
      "6/6 [==============================] - 0s 799us/step - loss: 0.6391 - accuracy: 0.5508\n",
      "Epoch 133/250\n",
      "6/6 [==============================] - 0s 940us/step - loss: 0.6379 - accuracy: 0.5615\n",
      "Epoch 134/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6368 - accuracy: 0.5615\n",
      "Epoch 135/250\n",
      "6/6 [==============================] - 0s 799us/step - loss: 0.6357 - accuracy: 0.5615\n",
      "Epoch 136/250\n",
      "6/6 [==============================] - 0s 600us/step - loss: 0.6346 - accuracy: 0.5615\n",
      "Epoch 137/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.6334 - accuracy: 0.5668\n",
      "Epoch 138/250\n",
      "6/6 [==============================] - 0s 741us/step - loss: 0.6323 - accuracy: 0.5668\n",
      "Epoch 139/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6312 - accuracy: 0.5668\n",
      "Epoch 140/250\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.6302 - accuracy: 0.5668\n",
      "Epoch 141/250\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.6291 - accuracy: 0.5668\n",
      "Epoch 142/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6280 - accuracy: 0.5722\n",
      "Epoch 143/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6269 - accuracy: 0.5722\n",
      "Epoch 144/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6258 - accuracy: 0.5722\n",
      "Epoch 145/250\n",
      "6/6 [==============================] - 0s 803us/step - loss: 0.6248 - accuracy: 0.5722\n",
      "Epoch 146/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6237 - accuracy: 0.5668\n",
      "Epoch 147/250\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.6227 - accuracy: 0.5775\n",
      "Epoch 148/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.6216 - accuracy: 0.5775\n",
      "Epoch 149/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6206 - accuracy: 0.5829\n",
      "Epoch 150/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.6195 - accuracy: 0.5775\n",
      "Epoch 151/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6186 - accuracy: 0.5775\n",
      "Epoch 152/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6175 - accuracy: 0.5775\n",
      "Epoch 153/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6165 - accuracy: 0.5829\n",
      "Epoch 154/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6155 - accuracy: 0.5829\n",
      "Epoch 155/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.6145 - accuracy: 0.5829\n",
      "Epoch 156/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6135 - accuracy: 0.5829\n",
      "Epoch 157/250\n",
      "6/6 [==============================] - 0s 610us/step - loss: 0.6126 - accuracy: 0.5882\n",
      "Epoch 158/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6116 - accuracy: 0.5882\n",
      "Epoch 159/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6106 - accuracy: 0.5882\n",
      "Epoch 160/250\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.6097 - accuracy: 0.5882\n",
      "Epoch 161/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.6087 - accuracy: 0.5882\n",
      "Epoch 162/250\n",
      "6/6 [==============================] - 0s 600us/step - loss: 0.6078 - accuracy: 0.5882\n",
      "Epoch 163/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6068 - accuracy: 0.5882\n",
      "Epoch 164/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 799us/step - loss: 0.6059 - accuracy: 0.5936\n",
      "Epoch 165/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6049 - accuracy: 0.5936\n",
      "Epoch 166/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6040 - accuracy: 0.5936\n",
      "Epoch 167/250\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.6031 - accuracy: 0.5936\n",
      "Epoch 168/250\n",
      "6/6 [==============================] - 0s 776us/step - loss: 0.6022 - accuracy: 0.5936\n",
      "Epoch 169/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.6012 - accuracy: 0.5936\n",
      "Epoch 170/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6004 - accuracy: 0.5936\n",
      "Epoch 171/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.5994 - accuracy: 0.5989\n",
      "Epoch 172/250\n",
      "6/6 [==============================] - 0s 599us/step - loss: 0.5985 - accuracy: 0.5989\n",
      "Epoch 173/250\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5977 - accuracy: 0.5989\n",
      "Epoch 174/250\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5968 - accuracy: 0.5989\n",
      "Epoch 175/250\n",
      "6/6 [==============================] - 0s 800us/step - loss: 0.5959 - accuracy: 0.5989\n",
      "Epoch 176/250\n",
      "6/6 [==============================] - 0s 600us/step - loss: 0.5951 - accuracy: 0.5989\n",
      "Epoch 177/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5942 - accuracy: 0.5989\n",
      "Epoch 178/250\n",
      "6/6 [==============================] - 0s 740us/step - loss: 0.5933 - accuracy: 0.5989\n",
      "Epoch 179/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5925 - accuracy: 0.5989\n",
      "Epoch 180/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.5916 - accuracy: 0.5989\n",
      "Epoch 181/250\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5908 - accuracy: 0.5936\n",
      "Epoch 182/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5900 - accuracy: 0.5936\n",
      "Epoch 183/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.5890 - accuracy: 0.5936\n",
      "Epoch 184/250\n",
      "6/6 [==============================] - 0s 600us/step - loss: 0.5883 - accuracy: 0.5936\n",
      "Epoch 185/250\n",
      "6/6 [==============================] - 0s 600us/step - loss: 0.5875 - accuracy: 0.5936\n",
      "Epoch 186/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5866 - accuracy: 0.5936\n",
      "Epoch 187/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5858 - accuracy: 0.5936\n",
      "Epoch 188/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5851 - accuracy: 0.5936\n",
      "Epoch 189/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5842 - accuracy: 0.5936\n",
      "Epoch 190/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5834 - accuracy: 0.5936\n",
      "Epoch 191/250\n",
      "6/6 [==============================] - 0s 400us/step - loss: 0.5826 - accuracy: 0.5936\n",
      "Epoch 192/250\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5818 - accuracy: 0.5936\n",
      "Epoch 193/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.5810 - accuracy: 0.5989\n",
      "Epoch 194/250\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5802 - accuracy: 0.5989\n",
      "Epoch 195/250\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5795 - accuracy: 0.5989\n",
      "Epoch 196/250\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5787 - accuracy: 0.5989\n",
      "Epoch 197/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5780 - accuracy: 0.6043\n",
      "Epoch 198/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5772 - accuracy: 0.6043\n",
      "Epoch 199/250\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5764 - accuracy: 0.6043\n",
      "Epoch 200/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5756 - accuracy: 0.6043\n",
      "Epoch 201/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5749 - accuracy: 0.6043\n",
      "Epoch 202/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5742 - accuracy: 0.6043\n",
      "Epoch 203/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5734 - accuracy: 0.6043\n",
      "Epoch 204/250\n",
      "6/6 [==============================] - 0s 799us/step - loss: 0.5727 - accuracy: 0.6043\n",
      "Epoch 205/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5719 - accuracy: 0.6043\n",
      "Epoch 206/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5712 - accuracy: 0.6043\n",
      "Epoch 207/250\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5705 - accuracy: 0.6043\n",
      "Epoch 208/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5698 - accuracy: 0.6043\n",
      "Epoch 209/250\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5691 - accuracy: 0.6043\n",
      "Epoch 210/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5684 - accuracy: 0.6043\n",
      "Epoch 211/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5676 - accuracy: 0.6096\n",
      "Epoch 212/250\n",
      "6/6 [==============================] - 0s 793us/step - loss: 0.5670 - accuracy: 0.6150\n",
      "Epoch 213/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5662 - accuracy: 0.6150\n",
      "Epoch 214/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5655 - accuracy: 0.6150\n",
      "Epoch 215/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5649 - accuracy: 0.6150\n",
      "Epoch 216/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5641 - accuracy: 0.6150\n",
      "Epoch 217/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5635 - accuracy: 0.6150\n",
      "Epoch 218/250\n",
      "6/6 [==============================] - 0s 988us/step - loss: 0.5628 - accuracy: 0.6150\n",
      "Epoch 219/250\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5621 - accuracy: 0.6150\n",
      "Epoch 220/250\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5614 - accuracy: 0.6150\n",
      "Epoch 221/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5607 - accuracy: 0.6150\n",
      "Epoch 222/250\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5601 - accuracy: 0.6150\n",
      "Epoch 223/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5594 - accuracy: 0.6150\n",
      "Epoch 224/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5587 - accuracy: 0.6150\n",
      "Epoch 225/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5581 - accuracy: 0.6150\n",
      "Epoch 226/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5574 - accuracy: 0.6150\n",
      "Epoch 227/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.5568 - accuracy: 0.6150\n",
      "Epoch 228/250\n",
      "6/6 [==============================] - 0s 992us/step - loss: 0.5561 - accuracy: 0.6150\n",
      "Epoch 229/250\n",
      "6/6 [==============================] - 0s 600us/step - loss: 0.5555 - accuracy: 0.6150\n",
      "Epoch 230/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.5549 - accuracy: 0.6150\n",
      "Epoch 231/250\n",
      "6/6 [==============================] - 0s 600us/step - loss: 0.5542 - accuracy: 0.6150\n",
      "Epoch 232/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5536 - accuracy: 0.6150\n",
      "Epoch 233/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5529 - accuracy: 0.6150\n",
      "Epoch 234/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5523 - accuracy: 0.6203\n",
      "Epoch 235/250\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5517 - accuracy: 0.6203\n",
      "Epoch 236/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.5511 - accuracy: 0.6203\n",
      "Epoch 237/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5504 - accuracy: 0.6203\n",
      "Epoch 238/250\n",
      "6/6 [==============================] - 0s 799us/step - loss: 0.5498 - accuracy: 0.6203\n",
      "Epoch 239/250\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5492 - accuracy: 0.6203\n",
      "Epoch 240/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5487 - accuracy: 0.6203\n",
      "Epoch 241/250\n",
      "6/6 [==============================] - 0s 825us/step - loss: 0.5480 - accuracy: 0.6257\n",
      "Epoch 242/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5474 - accuracy: 0.6257\n",
      "Epoch 243/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5468 - accuracy: 0.6257\n",
      "Epoch 244/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5462 - accuracy: 0.6257\n",
      "Epoch 245/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 601us/step - loss: 0.5456 - accuracy: 0.6257\n",
      "Epoch 246/250\n",
      "6/6 [==============================] - 0s 599us/step - loss: 0.5450 - accuracy: 0.6257\n",
      "Epoch 247/250\n",
      "6/6 [==============================] - 0s 746us/step - loss: 0.5444 - accuracy: 0.6257\n",
      "Epoch 248/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.5439 - accuracy: 0.6257\n",
      "Epoch 249/250\n",
      "6/6 [==============================] - 0s 736us/step - loss: 0.5432 - accuracy: 0.6257\n",
      "Epoch 250/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5427 - accuracy: 0.6257\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_moon_train, y_moon_train, epochs=250, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the fitting, we can retrieve the correctness information for the next matching steps (subsequent epochs) from the `history` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2d6821c6070>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your correctness is below 80%, you can run the model fitting cell (`model.fit(...)`) again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is worth noting that the solution reached by the network is tantamount to the logistic regression that we have already learned.\n",
    "This is because our network weighs predictors (values on the x and y axes in the graphic representation), adds up and transforms them logistically. Logistic regression does exactly the same - it selects weights for the predictors, adds up and transforms logistically. Logistic regression still has an `intercept`, but it is no different in the case of neural networks - every neuron has a so-called `bias`, which works exactly the same way as the `intercept`. As a result, we have implemented logistic regression using a neural network. We need more layers to be able to achieve better results.  \n",
    "However, before we move on to adding layers, we will check what correctness we get on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_correctness(X, y, clf, threshold=0.5):\n",
    "    probabilities = clf.predict(X)[:, 0]\n",
    "    predictions = (probabilities > threshold).astype('int')\n",
    "    correctness = (predictions == y).mean()\n",
    "    print('The correctness is: {:.2f}'.format(correctness))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correctness is: 0.67\n"
     ]
    }
   ],
   "source": [
    "show_correctness(X_moon_test, y_moon_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to increase model correctness. We will create a network with one hidden layer. We create the model the same way as before, we also create the output layer. Now, before we add the output layer, we add another layer with the following characteristics:\n",
    "* 3 neurons\n",
    "* Activation of the `relu` type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "üì∫ ************* WATCH AT HOME *************\n",
    "<br>\n",
    "\n",
    "[Which Activation Function Should I Use? - VERY GOOD VIDEO about RELU!](https://www.youtube.com/watch?v=-7scQpJT7uo)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(3, activation='relu', input_shape=(2,)))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compile and fit the model as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.7479 - accuracy: 0.2406\n",
      "Epoch 2/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.7444 - accuracy: 0.2620\n",
      "Epoch 3/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.7409 - accuracy: 0.2620\n",
      "Epoch 4/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.7375 - accuracy: 0.2674\n",
      "Epoch 5/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.7342 - accuracy: 0.2674\n",
      "Epoch 6/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.7312 - accuracy: 0.2727\n",
      "Epoch 7/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.7279 - accuracy: 0.2834\n",
      "Epoch 8/250\n",
      "6/6 [==============================] - 0s 800us/step - loss: 0.7249 - accuracy: 0.2460\n",
      "Epoch 9/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.7220 - accuracy: 0.5294\n",
      "Epoch 10/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.7190 - accuracy: 0.5561\n",
      "Epoch 11/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.7165 - accuracy: 0.5615\n",
      "Epoch 12/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.7136 - accuracy: 0.5615\n",
      "Epoch 13/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.7108 - accuracy: 0.5615\n",
      "Epoch 14/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.7081 - accuracy: 0.5615\n",
      "Epoch 15/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.7053 - accuracy: 0.5722\n",
      "Epoch 16/250\n",
      "6/6 [==============================] - 0s 800us/step - loss: 0.7028 - accuracy: 0.5722\n",
      "Epoch 17/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.7001 - accuracy: 0.5775\n",
      "Epoch 18/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6974 - accuracy: 0.5775\n",
      "Epoch 19/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6948 - accuracy: 0.5775\n",
      "Epoch 20/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6919 - accuracy: 0.5882\n",
      "Epoch 21/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6892 - accuracy: 0.5829\n",
      "Epoch 22/250\n",
      "6/6 [==============================] - 0s 600us/step - loss: 0.6864 - accuracy: 0.5882\n",
      "Epoch 23/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.6835 - accuracy: 0.5882\n",
      "Epoch 24/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6808 - accuracy: 0.5882\n",
      "Epoch 25/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.6778 - accuracy: 0.5882\n",
      "Epoch 26/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6750 - accuracy: 0.5882\n",
      "Epoch 27/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6719 - accuracy: 0.5829\n",
      "Epoch 28/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6689 - accuracy: 0.5936\n",
      "Epoch 29/250\n",
      "6/6 [==============================] - 0s 603us/step - loss: 0.6658 - accuracy: 0.5936\n",
      "Epoch 30/250\n",
      "6/6 [==============================] - 0s 600us/step - loss: 0.6627 - accuracy: 0.6043\n",
      "Epoch 31/250\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.6596 - accuracy: 0.6043\n",
      "Epoch 32/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.6565 - accuracy: 0.6043\n",
      "Epoch 33/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6532 - accuracy: 0.6043\n",
      "Epoch 34/250\n",
      "6/6 [==============================] - 0s 803us/step - loss: 0.6500 - accuracy: 0.6096\n",
      "Epoch 35/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6467 - accuracy: 0.6096\n",
      "Epoch 36/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6432 - accuracy: 0.6096\n",
      "Epoch 37/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6397 - accuracy: 0.6096\n",
      "Epoch 38/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.6363 - accuracy: 0.6150\n",
      "Epoch 39/250\n",
      "6/6 [==============================] - 0s 802us/step - loss: 0.6326 - accuracy: 0.6203\n",
      "Epoch 40/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.6291 - accuracy: 0.6257\n",
      "Epoch 41/250\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.6255 - accuracy: 0.6257\n",
      "Epoch 42/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6219 - accuracy: 0.6257\n",
      "Epoch 43/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6182 - accuracy: 0.6257\n",
      "Epoch 44/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6145 - accuracy: 0.6257\n",
      "Epoch 45/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6109 - accuracy: 0.6364\n",
      "Epoch 46/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6071 - accuracy: 0.6471\n",
      "Epoch 47/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6035 - accuracy: 0.6524\n",
      "Epoch 48/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6002 - accuracy: 0.6578\n",
      "Epoch 49/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5965 - accuracy: 0.6684\n",
      "Epoch 50/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.5931 - accuracy: 0.6684\n",
      "Epoch 51/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.5900 - accuracy: 0.6684\n",
      "Epoch 52/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5867 - accuracy: 0.6684\n",
      "Epoch 53/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5834 - accuracy: 0.6684\n",
      "Epoch 54/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.5802 - accuracy: 0.6738\n",
      "Epoch 55/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5770 - accuracy: 0.6738\n",
      "Epoch 56/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5737 - accuracy: 0.6738\n",
      "Epoch 57/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.5708 - accuracy: 0.6738\n",
      "Epoch 58/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5678 - accuracy: 0.6738\n",
      "Epoch 59/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.5646 - accuracy: 0.6738\n",
      "Epoch 60/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5616 - accuracy: 0.6738\n",
      "Epoch 61/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5588 - accuracy: 0.6738\n",
      "Epoch 62/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5559 - accuracy: 0.6791\n",
      "Epoch 63/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5530 - accuracy: 0.6845\n",
      "Epoch 64/250\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5503 - accuracy: 0.6791\n",
      "Epoch 65/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.5474 - accuracy: 0.6791\n",
      "Epoch 66/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5451 - accuracy: 0.6845\n",
      "Epoch 67/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.5424 - accuracy: 0.6898\n",
      "Epoch 68/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5400 - accuracy: 0.6898\n",
      "Epoch 69/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.5376 - accuracy: 0.6898\n",
      "Epoch 70/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.5353 - accuracy: 0.6898\n",
      "Epoch 71/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.5330 - accuracy: 0.6898\n",
      "Epoch 72/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5308 - accuracy: 0.6845\n",
      "Epoch 73/250\n",
      "6/6 [==============================] - 0s 600us/step - loss: 0.5288 - accuracy: 0.6898\n",
      "Epoch 74/250\n",
      "6/6 [==============================] - 0s 600us/step - loss: 0.5265 - accuracy: 0.6898\n",
      "Epoch 75/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5243 - accuracy: 0.6898\n",
      "Epoch 76/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5224 - accuracy: 0.6898\n",
      "Epoch 77/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5203 - accuracy: 0.6898\n",
      "Epoch 78/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5184 - accuracy: 0.6952\n",
      "Epoch 79/250\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5165 - accuracy: 0.7005\n",
      "Epoch 80/250\n",
      "6/6 [==============================] - 0s 600us/step - loss: 0.5146 - accuracy: 0.7005\n",
      "Epoch 81/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.5128 - accuracy: 0.7005\n",
      "Epoch 82/250\n",
      "6/6 [==============================] - 0s 600us/step - loss: 0.5111 - accuracy: 0.6898\n",
      "Epoch 83/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 801us/step - loss: 0.5092 - accuracy: 0.6898\n",
      "Epoch 84/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5076 - accuracy: 0.6898\n",
      "Epoch 85/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5059 - accuracy: 0.6898\n",
      "Epoch 86/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.5042 - accuracy: 0.6898\n",
      "Epoch 87/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.5027 - accuracy: 0.6898\n",
      "Epoch 88/250\n",
      "6/6 [==============================] - 0s 600us/step - loss: 0.5011 - accuracy: 0.6898\n",
      "Epoch 89/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4996 - accuracy: 0.6898\n",
      "Epoch 90/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4981 - accuracy: 0.6898\n",
      "Epoch 91/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4966 - accuracy: 0.6898\n",
      "Epoch 92/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.4951 - accuracy: 0.6898\n",
      "Epoch 93/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4937 - accuracy: 0.6952\n",
      "Epoch 94/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4922 - accuracy: 0.7005\n",
      "Epoch 95/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4908 - accuracy: 0.7005\n",
      "Epoch 96/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.4895 - accuracy: 0.7005\n",
      "Epoch 97/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4881 - accuracy: 0.7005\n",
      "Epoch 98/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.4867 - accuracy: 0.7005\n",
      "Epoch 99/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4855 - accuracy: 0.7005\n",
      "Epoch 100/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.4842 - accuracy: 0.7005\n",
      "Epoch 101/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4830 - accuracy: 0.7005\n",
      "Epoch 102/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4817 - accuracy: 0.7005\n",
      "Epoch 103/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4805 - accuracy: 0.7005\n",
      "Epoch 104/250\n",
      "6/6 [==============================] - 0s 600us/step - loss: 0.4792 - accuracy: 0.7005\n",
      "Epoch 105/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.4781 - accuracy: 0.7005\n",
      "Epoch 106/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4770 - accuracy: 0.7005\n",
      "Epoch 107/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4759 - accuracy: 0.7005\n",
      "Epoch 108/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.4747 - accuracy: 0.7273\n",
      "Epoch 109/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.4737 - accuracy: 0.7273\n",
      "Epoch 110/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4726 - accuracy: 0.7273\n",
      "Epoch 111/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4714 - accuracy: 0.7273\n",
      "Epoch 112/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4704 - accuracy: 0.7273\n",
      "Epoch 113/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4694 - accuracy: 0.7273\n",
      "Epoch 114/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4683 - accuracy: 0.7380\n",
      "Epoch 115/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4674 - accuracy: 0.7380\n",
      "Epoch 116/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.4663 - accuracy: 0.7380\n",
      "Epoch 117/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4653 - accuracy: 0.7380\n",
      "Epoch 118/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.4643 - accuracy: 0.7487\n",
      "Epoch 119/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.4634 - accuracy: 0.7487\n",
      "Epoch 120/250\n",
      "6/6 [==============================] - 0s 600us/step - loss: 0.4624 - accuracy: 0.7540\n",
      "Epoch 121/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4614 - accuracy: 0.7540\n",
      "Epoch 122/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4605 - accuracy: 0.7540\n",
      "Epoch 123/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.4595 - accuracy: 0.7540\n",
      "Epoch 124/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4585 - accuracy: 0.7540\n",
      "Epoch 125/250\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4576 - accuracy: 0.7540\n",
      "Epoch 126/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4566 - accuracy: 0.7594\n",
      "Epoch 127/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4557 - accuracy: 0.7647\n",
      "Epoch 128/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4548 - accuracy: 0.7647\n",
      "Epoch 129/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4539 - accuracy: 0.7647\n",
      "Epoch 130/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4530 - accuracy: 0.7647\n",
      "Epoch 131/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.4521 - accuracy: 0.7647\n",
      "Epoch 132/250\n",
      "6/6 [==============================] - 0s 802us/step - loss: 0.4512 - accuracy: 0.7701\n",
      "Epoch 133/250\n",
      "6/6 [==============================] - 0s 600us/step - loss: 0.4504 - accuracy: 0.7701\n",
      "Epoch 134/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.4495 - accuracy: 0.7701\n",
      "Epoch 135/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4486 - accuracy: 0.7701\n",
      "Epoch 136/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4478 - accuracy: 0.7701\n",
      "Epoch 137/250\n",
      "6/6 [==============================] - 0s 600us/step - loss: 0.4470 - accuracy: 0.7701\n",
      "Epoch 138/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.4461 - accuracy: 0.7701\n",
      "Epoch 139/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4454 - accuracy: 0.7701\n",
      "Epoch 140/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4445 - accuracy: 0.7701\n",
      "Epoch 141/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.4437 - accuracy: 0.7701\n",
      "Epoch 142/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4430 - accuracy: 0.7701\n",
      "Epoch 143/250\n",
      "6/6 [==============================] - 0s 600us/step - loss: 0.4423 - accuracy: 0.7701\n",
      "Epoch 144/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4414 - accuracy: 0.7754\n",
      "Epoch 145/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.4407 - accuracy: 0.7754\n",
      "Epoch 146/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4399 - accuracy: 0.7754\n",
      "Epoch 147/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4392 - accuracy: 0.7754\n",
      "Epoch 148/250\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4384 - accuracy: 0.7754\n",
      "Epoch 149/250\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4377 - accuracy: 0.7754\n",
      "Epoch 150/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4370 - accuracy: 0.7754\n",
      "Epoch 151/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4363 - accuracy: 0.7754\n",
      "Epoch 152/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4355 - accuracy: 0.7807\n",
      "Epoch 153/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.4348 - accuracy: 0.7807\n",
      "Epoch 154/250\n",
      "6/6 [==============================] - 0s 600us/step - loss: 0.4341 - accuracy: 0.7807\n",
      "Epoch 155/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.4334 - accuracy: 0.7807\n",
      "Epoch 156/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4327 - accuracy: 0.7807\n",
      "Epoch 157/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4321 - accuracy: 0.7807\n",
      "Epoch 158/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4313 - accuracy: 0.7807\n",
      "Epoch 159/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4306 - accuracy: 0.7807\n",
      "Epoch 160/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4299 - accuracy: 0.7807\n",
      "Epoch 161/250\n",
      "6/6 [==============================] - 0s 799us/step - loss: 0.4292 - accuracy: 0.7807\n",
      "Epoch 162/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.4286 - accuracy: 0.7807\n",
      "Epoch 163/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.4279 - accuracy: 0.7807\n",
      "Epoch 164/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 601us/step - loss: 0.4272 - accuracy: 0.7861\n",
      "Epoch 165/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4266 - accuracy: 0.7861\n",
      "Epoch 166/250\n",
      "6/6 [==============================] - 0s 800us/step - loss: 0.4259 - accuracy: 0.7861\n",
      "Epoch 167/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4254 - accuracy: 0.7861\n",
      "Epoch 168/250\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4247 - accuracy: 0.7861\n",
      "Epoch 169/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4241 - accuracy: 0.7968\n",
      "Epoch 170/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4235 - accuracy: 0.7968\n",
      "Epoch 171/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4229 - accuracy: 0.7968\n",
      "Epoch 172/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4223 - accuracy: 0.7968\n",
      "Epoch 173/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.4217 - accuracy: 0.7968\n",
      "Epoch 174/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4212 - accuracy: 0.8021\n",
      "Epoch 175/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.4206 - accuracy: 0.8021\n",
      "Epoch 176/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.4200 - accuracy: 0.8021\n",
      "Epoch 177/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4194 - accuracy: 0.8021\n",
      "Epoch 178/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4189 - accuracy: 0.8075\n",
      "Epoch 179/250\n",
      "6/6 [==============================] - 0s 600us/step - loss: 0.4183 - accuracy: 0.8075\n",
      "Epoch 180/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4178 - accuracy: 0.8075\n",
      "Epoch 181/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4172 - accuracy: 0.8075\n",
      "Epoch 182/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4167 - accuracy: 0.8075\n",
      "Epoch 183/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.4161 - accuracy: 0.8075\n",
      "Epoch 184/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4156 - accuracy: 0.8075\n",
      "Epoch 185/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.4150 - accuracy: 0.8075\n",
      "Epoch 186/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4144 - accuracy: 0.8075\n",
      "Epoch 187/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4140 - accuracy: 0.8075\n",
      "Epoch 188/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4134 - accuracy: 0.8075\n",
      "Epoch 189/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.4129 - accuracy: 0.8075\n",
      "Epoch 190/250\n",
      "6/6 [==============================] - 0s 600us/step - loss: 0.4124 - accuracy: 0.8075\n",
      "Epoch 191/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.4119 - accuracy: 0.8075\n",
      "Epoch 192/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4114 - accuracy: 0.8075\n",
      "Epoch 193/250\n",
      "6/6 [==============================] - 0s 600us/step - loss: 0.4109 - accuracy: 0.8075\n",
      "Epoch 194/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4104 - accuracy: 0.8075\n",
      "Epoch 195/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.4099 - accuracy: 0.8075\n",
      "Epoch 196/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4094 - accuracy: 0.8075\n",
      "Epoch 197/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4090 - accuracy: 0.8075\n",
      "Epoch 198/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4084 - accuracy: 0.8075\n",
      "Epoch 199/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4080 - accuracy: 0.8075\n",
      "Epoch 200/250\n",
      "6/6 [==============================] - 0s 799us/step - loss: 0.4075 - accuracy: 0.8075\n",
      "Epoch 201/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4071 - accuracy: 0.8075\n",
      "Epoch 202/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4065 - accuracy: 0.8075\n",
      "Epoch 203/250\n",
      "6/6 [==============================] - 0s 600us/step - loss: 0.4061 - accuracy: 0.8075\n",
      "Epoch 204/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4056 - accuracy: 0.8075\n",
      "Epoch 205/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4052 - accuracy: 0.8075\n",
      "Epoch 206/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4047 - accuracy: 0.8075\n",
      "Epoch 207/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.4042 - accuracy: 0.8075\n",
      "Epoch 208/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4038 - accuracy: 0.8075\n",
      "Epoch 209/250\n",
      "6/6 [==============================] - 0s 600us/step - loss: 0.4033 - accuracy: 0.8075\n",
      "Epoch 210/250\n",
      "6/6 [==============================] - 0s 600us/step - loss: 0.4029 - accuracy: 0.8075\n",
      "Epoch 211/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4024 - accuracy: 0.8075\n",
      "Epoch 212/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4020 - accuracy: 0.8075\n",
      "Epoch 213/250\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4015 - accuracy: 0.8075\n",
      "Epoch 214/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4011 - accuracy: 0.8075\n",
      "Epoch 215/250\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4007 - accuracy: 0.8075\n",
      "Epoch 216/250\n",
      "6/6 [==============================] - 0s 864us/step - loss: 0.4002 - accuracy: 0.8075\n",
      "Epoch 217/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.3998 - accuracy: 0.8075\n",
      "Epoch 218/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.3995 - accuracy: 0.8075\n",
      "Epoch 219/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.3990 - accuracy: 0.8075\n",
      "Epoch 220/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.3986 - accuracy: 0.8075\n",
      "Epoch 221/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.3982 - accuracy: 0.8075\n",
      "Epoch 222/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.3978 - accuracy: 0.8075\n",
      "Epoch 223/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.3975 - accuracy: 0.8021\n",
      "Epoch 224/250\n",
      "6/6 [==============================] - 0s 600us/step - loss: 0.3971 - accuracy: 0.8021\n",
      "Epoch 225/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.3967 - accuracy: 0.8021\n",
      "Epoch 226/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.3964 - accuracy: 0.8021\n",
      "Epoch 227/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.3960 - accuracy: 0.8021\n",
      "Epoch 228/250\n",
      "6/6 [==============================] - 0s 600us/step - loss: 0.3956 - accuracy: 0.8021\n",
      "Epoch 229/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.3953 - accuracy: 0.8021\n",
      "Epoch 230/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.3950 - accuracy: 0.8021\n",
      "Epoch 231/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.3946 - accuracy: 0.8021\n",
      "Epoch 232/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.3943 - accuracy: 0.8021\n",
      "Epoch 233/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.3939 - accuracy: 0.8021\n",
      "Epoch 234/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.3936 - accuracy: 0.8075\n",
      "Epoch 235/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.3932 - accuracy: 0.8075\n",
      "Epoch 236/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.3929 - accuracy: 0.8075\n",
      "Epoch 237/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.3926 - accuracy: 0.8075\n",
      "Epoch 238/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.3923 - accuracy: 0.8075\n",
      "Epoch 239/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.3919 - accuracy: 0.8075\n",
      "Epoch 240/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.3916 - accuracy: 0.8075\n",
      "Epoch 241/250\n",
      "6/6 [==============================] - 0s 600us/step - loss: 0.3913 - accuracy: 0.8075\n",
      "Epoch 242/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.3909 - accuracy: 0.8075\n",
      "Epoch 243/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.3906 - accuracy: 0.8075\n",
      "Epoch 244/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.3904 - accuracy: 0.8075\n",
      "Epoch 245/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 801us/step - loss: 0.3900 - accuracy: 0.8075\n",
      "Epoch 246/250\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.3897 - accuracy: 0.8075\n",
      "Epoch 247/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.3894 - accuracy: 0.8075\n",
      "Epoch 248/250\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.3891 - accuracy: 0.8128\n",
      "Epoch 249/250\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.3888 - accuracy: 0.8128\n",
      "Epoch 250/250\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.3886 - accuracy: 0.8128\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_moon_train, y_moon_train, epochs=250, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2d683305af0>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "‚ö†Ô∏èTASK 4\n",
    "<br>\n",
    "\n",
    "Now check the correctness of this network for the test data.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3242 - accuracy: 0.8889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3241880238056183, 0.8888888955116272]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_moon_test, y_moon_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "‚ö†Ô∏èTASK 5\n",
    "<br>\n",
    "\n",
    "Create a model with two hidden layers: one with 8 neurons, the other with 2. Both hidden layers with activation of `'relu'` type.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating model\n",
    "model = Sequential()\n",
    "\n",
    "# hidden layers\n",
    "model.add(Dense(_, activation=______, input_shape=(2,)))\n",
    "model.add(Dense(_, activation=______))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling, training, and plotting the accuracy history\n",
    "model.compile(loss=_________________, optimizer=_______, metrics=___________)\n",
    "history = model.fit(_____________, ____________, epochs=350, verbose=0)\n",
    "plt.plot(history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "‚ö†Ô∏èTASK 6\n",
    "<br>\n",
    "\n",
    "Now check the correctness of this network for the test data.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "‚ö†Ô∏èTASK 7\n",
    "<br>\n",
    "\n",
    "Build the same model as in the first exercise, but now the second hidden layer should have 10 neurons.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here the code creating the network\n",
    "model = ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer=______, metrics=['accuracy'])\n",
    "history = model.fit(X_moon_train, y_moon_train, epochs=350, verbose=0)\n",
    "plt.plot(history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision(_________, __________, clf=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "‚ö†Ô∏èTASK 8\n",
    "<br>\n",
    "\n",
    "Now check the correctness of this network for the test data.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you see what the correctness is right now???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back to the Titanic\n",
    "First, create a network with two hidden layers - 10 neurons each.\n",
    "We will now use titanic data; also note that we have a different number of predicators here, which we have to provide to `input_shape`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "‚ö†Ô∏èTASK 9\n",
    "<br>\n",
    "\n",
    "Now create a network to classify survival on Titanic.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During model training we would like to see how the correctness of the test data changes with training.\n",
    "We can do this by giving an additional argument of `validation_data` and setting it to `(X_test_std, y_test)`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the case of previous algorithms, in the case of neural networks we are also dealing with hyperparameters. The most obvious hyperparameters of neural networks are: \n",
    "- the number of layers, \n",
    "- number of neurons in each layer,\n",
    "- activation types,\n",
    "- regularization (regular or dropout - but we will talk about it later), \n",
    "- finally: matching algorithm, learning rate (how big steps in the searched parameter space are performed) and others. \n",
    "\n",
    "We won't learn how to match hyperparameters for the network (apart from choosing the number of layers and neurons), but it's worth remembering that there is such a possibility. Professional applications of neural networks usually perform tests on many lists of hyperparameters (especially those hyperparameters that are not network architectures)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
